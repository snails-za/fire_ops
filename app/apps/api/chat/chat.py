"""
æ™ºèƒ½é—®ç­”APIæ¨¡å—

æä¾›åŸºäºŽRAGçš„æ™ºèƒ½é—®ç­”æœåŠ¡ï¼ŒåŒ…æ‹¬ï¼š
1. æ™ºèƒ½é—®ç­” - åŸºäºŽæ–‡æ¡£å†…å®¹çš„AIé—®ç­”
2. æ–‡æ¡£æœç´¢ - è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢
3. é—®é¢˜åˆ†æž - LLMé—®é¢˜ç†è§£å’Œä¼˜åŒ–

é›†æˆäº†LangChainå’ŒOpenAIï¼Œæ”¯æŒé—®é¢˜ä¼˜åŒ–å’Œæœç´¢å¢žå¼ºã€‚
"""

import json
import traceback

from fastapi import APIRouter, Query, Form
from fastapi.responses import StreamingResponse

from apps.utils import response
from apps.utils.llm_optimizers import get_question_optimizer, get_search_optimizer, optimize_question
from apps.utils.rag_helper import vector_search, rag_generator
from config import SIMILARITY_THRESHOLD

# æ™ºèƒ½é—®ç­”APIè·¯ç”±
router = APIRouter(prefix="/chat", tags=["æ™ºèƒ½é—®ç­”"])


@router.post("/ask/stream", summary="æµå¼æ™ºèƒ½é—®ç­”", description="åŸºäºŽLLMçš„æµå¼æ™ºèƒ½æ–‡æ¡£é—®ç­”")
async def ask_question_stream(
    question: str = Form(..., description="ç”¨æˆ·é—®é¢˜"),
    top_k: int = Form(5, ge=1, le=10, description="æ£€ç´¢ç›¸å…³æ–‡æ¡£æ•°é‡"),
):
    """
    æµå¼æ™ºèƒ½é—®ç­” - å®žæ—¶è¾“å‡ºå›žç­”å†…å®¹
    """
    async def generate_stream():
        try:
            # 1. é—®é¢˜ç†è§£å’Œä¼˜åŒ–
            question_analysis = None
            optimized_query = question
            
            question_optimizer = get_question_optimizer()
            search_optimizer = get_search_optimizer()
            
            if question_optimizer:
                try:
                    analysis_result = optimize_question(question)
                    if analysis_result:
                        question_analysis = analysis_result
                        optimized_query = analysis_result.get("optimized_query", question)
                    else:
                        # å¦‚æžœé—®é¢˜åˆ†æžå¤±è´¥ï¼Œä½¿ç”¨æœç´¢ä¼˜åŒ–å™¨
                        if search_optimizer:
                            try:
                                optimized_query = search_optimizer.invoke({"question": question})
                                optimized_query = optimized_query.strip()
                                if not optimized_query:
                                    optimized_query = question
                            except Exception as e:
                                print(f"æœç´¢ä¼˜åŒ–å¤±è´¥: {e}")
                                optimized_query = question
                except Exception as e:
                    print(f"é—®é¢˜ä¼˜åŒ–å¤±è´¥: {e}")
                    optimized_query = question
            
            # å‘é€æœç´¢çŠ¶æ€
            yield f"data: {json.dumps({'type': 'status', 'message': 'ðŸ” æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£...'}, ensure_ascii=False)}\n\n"
            
            # 2. å‘é‡æœç´¢ç›¸å…³æ–‡æ¡£ï¼ˆä½¿ç”¨MMRç®—æ³•ï¼‰
            search_results = await vector_search.search_similar_documents(
                query=optimized_query,
                top_k=top_k,
                use_threshold=True
            )
            
            if not search_results:
                yield f"data: {json.dumps({'type': 'content', 'message': 'æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ–‡æ¡£å†…å®¹æ¥å›žç­”æ‚¨çš„é—®é¢˜ã€‚'}, ensure_ascii=False)}\n\n"
                return
            
            # å‘é€æ–‡æ¡£ä¿¡æ¯
            high_quality_results = [r for r in search_results if r.get('above_threshold', True)]
            low_quality_results = [r for r in search_results if not r.get('above_threshold', True)]
            
            # æž„å»ºæºä¿¡æ¯
            sources = []
            for result in search_results:
                document = result.get("document")
                chunk = result.get("chunk")
                chunk_content = chunk.content if chunk else ""
                sources.append({
                    "document_name": document.filename if document else "æœªçŸ¥æ–‡æ¡£",
                    "original_filename": document.original_filename if document else None,
                    "file_type": document.file_type if document else None,
                    "chunk_text": chunk_content,
                    "content_preview": chunk_content[:200] + "..." if len(chunk_content) > 200 else chunk_content,
                    "similarity": round(result.get("similarity", 0), 4),
                    "document_id": document.id if document else None,
                    "chunk_id": chunk.id if chunk else None,
                    "chunk_index": chunk.chunk_index if chunk else 0,
                    "above_threshold": result.get("above_threshold", True)
                })
            
            # å‘é€æœç´¢ç»“æžœä¿¡æ¯
            search_info = {
                "search_count": len(search_results),
                "high_quality_count": len(high_quality_results),
                "low_quality_count": len(low_quality_results),
                "similarity_threshold": SIMILARITY_THRESHOLD,
                "result_quality": "high" if high_quality_results else ("low" if low_quality_results else "none"),
                "optimized_query": optimized_query,
                "question_analysis": question_analysis
            }

            # æ·»åŠ é—®é¢˜åˆ†æžçš„å…³é”®è¯ä¿¡æ¯
            keywords = []
            if question_analysis and 'keywords' in question_analysis:
                keywords = question_analysis['keywords']
            elif optimized_query and optimized_query != question:
                # å¦‚æžœæ²¡æœ‰å…³é”®è¯ä½†æœ‰ä¼˜åŒ–æŸ¥è¯¢ï¼Œä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢ä½œä¸ºå…³é”®è¯
                keywords = [optimized_query]
            
            yield f"data: {json.dumps({'type': 'sources', 'sources': sources, 'search_info': search_info, 'keywords': keywords}, ensure_ascii=False)}\n\n"
            yield f"data: {json.dumps({'type': 'status', 'message': 'ðŸ¤– æ­£åœ¨ç”Ÿæˆå›žç­”...'}, ensure_ascii=False)}\n\n"
            
            # 3. ç”ŸæˆçœŸæ­£çš„æµå¼å›žç­”
            current_text = ""
            
            # ä½¿ç”¨RAGç”Ÿæˆå™¨çš„æµå¼æ–¹æ³•
            async for chunk in rag_generator.generate_answer_stream(
                query=question,
                context_chunks=search_results
            ):
                if chunk:
                    current_text += chunk
                    yield f"data: {json.dumps({'type': 'content', 'content': current_text}, ensure_ascii=False)}\n\n"
            
            # æ ¹æ®ç»“æžœè´¨é‡æ·»åŠ æç¤º
            if low_quality_results:
                additional_tip = "\n\nðŸ’¡ æç¤ºï¼šä»¥ä¸Šå›žç­”åŸºäºŽç›¸ä¼¼åº¦è¾ƒä½Žçš„æ–‡æ¡£å†…å®¹ï¼Œå¯èƒ½ä¸å¤Ÿå‡†ç¡®ã€‚å»ºè®®æ‚¨ï¼š\nâ€¢ å°è¯•æ›´å…·ä½“çš„é—®é¢˜æè¿°\nâ€¢ ä½¿ç”¨ä¸åŒçš„å…³é”®è¯é‡æ–°æé—®"
                current_text += additional_tip
                yield f"data: {json.dumps({'type': 'content', 'content': current_text}, ensure_ascii=False)}\n\n"
            
            # å‘é€å®Œæˆä¿¡å·
            yield f"data: {json.dumps({'type': 'done'}, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            print(f"æµå¼é—®ç­”å¤±è´¥: {e}")
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'message': f'é—®ç­”å¤±è´¥: {str(e)}'}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/event-stream",
        }
    )


@router.post("/ask", summary="æ™ºèƒ½é—®ç­”(åŒ¿å)", description="åŸºäºŽLLMçš„æ™ºèƒ½æ–‡æ¡£é—®ç­”ï¼ˆæ— éœ€ç™»å½•ï¼‰")
async def ask_question_anonymous(
    question: str = Form(..., description="ç”¨æˆ·é—®é¢˜"),
    top_k: int = Form(5, ge=1, le=10, description="æ£€ç´¢ç›¸å…³æ–‡æ¡£æ•°é‡"),
):
    """
    åŒ¿åæ™ºèƒ½é—®ç­” - é›†æˆLLMé—®é¢˜ç†è§£å’Œæœç´¢ä¼˜åŒ–
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        top_k: æ£€ç´¢ç›¸å…³æ–‡æ¡£æ•°é‡
        
    Returns:
        æ™ºèƒ½é—®ç­”ç»“æžœï¼ŒåŒ…å«ç­”æ¡ˆã€ç›¸å…³æ–‡æ¡£å’Œé—®é¢˜åˆ†æž
    """
    try:
        # 1. é—®é¢˜ç†è§£å’Œä¼˜åŒ–
        question_analysis = None
        optimized_query = question
        
        # ä½¿ç”¨æ–°çš„ä¼˜åŒ–å™¨æ¨¡å—
        question_optimizer = get_question_optimizer()
        search_optimizer = get_search_optimizer()
        
        if question_optimizer:
            try:
                # ä½¿ç”¨æ–°çš„ç»“æž„åŒ–è¾“å‡º
                analysis_result = optimize_question(question)
                
                if analysis_result:
                    question_analysis = analysis_result
                    optimized_query = analysis_result.get("optimized_query", question)
                else:
                    # å¦‚æžœé—®é¢˜åˆ†æžå¤±è´¥ï¼Œä½¿ç”¨æœç´¢ä¼˜åŒ–å™¨
                    if search_optimizer:
                        try:
                            optimized_query = search_optimizer.invoke({"question": question})
                            optimized_query = optimized_query.strip()
                            if not optimized_query:
                                optimized_query = question
                        except Exception as e:
                            print(f"æœç´¢ä¼˜åŒ–å¤±è´¥: {e}")
                            optimized_query = question
                    
            except Exception as e:
                print(f"é—®é¢˜ä¼˜åŒ–å¤±è´¥: {e}")
                optimized_query = question
        
        # 2. å‘é‡æœç´¢ç›¸å…³æ–‡æ¡£
        search_results = await vector_search.search_similar_documents(
            query=optimized_query,
            top_k=top_k,
            use_threshold=True,  # ä¸ä½¿ç”¨é˜ˆå€¼è¿‡æ»¤ï¼Œè¿”å›žæ‰€æœ‰æ‰¾åˆ°çš„ç»“æžœ
            lambda_param=0.7  # MMRå‚æ•°ï¼š0.7è¡¨ç¤º70%ç›¸å…³æ€§ï¼Œ30%å¤šæ ·æ€§
        )
        
        if not search_results:
            return response(
                data={
                    "answer": "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ–‡æ¡£å†…å®¹æ¥å›žç­”æ‚¨çš„é—®é¢˜ã€‚è¯·å°è¯•ï¼š\n1. é‡æ–°è¡¨è¿°é—®é¢˜\n2. ä½¿ç”¨æ›´å…·ä½“çš„å…³é”®è¯\n3. ç¡®ä¿ç›¸å…³æ–‡æ¡£å·²ä¸Šä¼ ",
                    "sources": [],
                    "question_analysis": question_analysis,
                    "optimized_query": optimized_query,
                    "search_count": 0,
                    "similarity_threshold": SIMILARITY_THRESHOLD
                },
                message="æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"
            )
        
        # 3. åˆ†æžæœç´¢ç»“æžœè´¨é‡å¹¶ç”Ÿæˆæ™ºèƒ½å›žç­”
        high_quality_results = [r for r in search_results if r.get('above_threshold', True)]
        low_quality_results = [r for r in search_results if not r.get('above_threshold', True)]
        
        # ç”ŸæˆåŸºç¡€å›žç­”
        answer = await rag_generator.generate_answer(
            query=question,
            context_chunks=search_results
        )
        
        # æ ¹æ®ç»“æžœè´¨é‡è°ƒæ•´å›žç­”
        if low_quality_results:
            # åªæœ‰ä½Žè´¨é‡ç»“æžœï¼Œæ·»åŠ æç¤º
            answer = f"{answer}\n\nðŸ’¡ æç¤ºï¼šä»¥ä¸Šå›žç­”åŸºäºŽç›¸ä¼¼åº¦è¾ƒä½Žçš„æ–‡æ¡£å†…å®¹ï¼Œå¯èƒ½ä¸å¤Ÿå‡†ç¡®ã€‚å»ºè®®æ‚¨ï¼š\nâ€¢ å°è¯•æ›´å…·ä½“çš„é—®é¢˜æè¿°\nâ€¢ ä½¿ç”¨ä¸åŒçš„å…³é”®è¯é‡æ–°æé—®"
        
        # 4. æž„å»ºæºä¿¡æ¯
        sources = []
        for result in search_results:
            # ä»Žresultä¸­æå–documentå’Œchunkå¯¹è±¡
            document = result.get("document")
            chunk = result.get("chunk")
            
            chunk_content = chunk.content if chunk else ""
            sources.append({
                "document_name": document.filename if document else "æœªçŸ¥æ–‡æ¡£",
                "original_filename": document.original_filename if document else None,
                "file_type": document.file_type if document else None,
                "chunk_text": chunk_content,
                "content_preview": chunk_content[:200] + "..." if len(chunk_content) > 200 else chunk_content,
                "similarity": round(result.get("similarity", 0), 4),
                "document_id": document.id if document else None,
                "chunk_id": chunk.id if chunk else None,
                "chunk_index": chunk.chunk_index if chunk else 0
            })
        
        return response(
            data={
                "answer": answer,
                "sources": sources,
                "question_analysis": question_analysis,
                "optimized_query": optimized_query,
                "search_count": len(search_results),
                "high_quality_count": len(high_quality_results),
                "low_quality_count": len(low_quality_results),
                "similarity_threshold": SIMILARITY_THRESHOLD,
                "result_quality": "high" if high_quality_results else ("low" if low_quality_results else "none")
            },
            message="é—®ç­”æˆåŠŸ"
        )
        
    except Exception as e:
        print(f"æ™ºèƒ½é—®ç­”å¤±è´¥: {e}")
        traceback.print_exc()
        return response(code=0, message=f"é—®ç­”å¤±è´¥: {str(e)}")


@router.get("/search", summary="æ–‡æ¡£æœç´¢(åŒ¿å)", description="åŸºäºŽLLMä¼˜åŒ–çš„æ–‡æ¡£æœç´¢ï¼ˆæ— éœ€ç™»å½•ï¼‰")
async def search_documents(
    query: str,
    top_k: int = Query(5, ge=1, le=20, description="è¿”å›žç»“æžœæ•°é‡"),
):
    """æœç´¢ç›¸å…³æ–‡æ¡£ - é›†æˆLLMæŸ¥è¯¢ä¼˜åŒ–"""
    try:
        original_query = query.strip()
        search_query = original_query
        
        # ä½¿ç”¨æ–°çš„ä¼˜åŒ–å™¨æ¨¡å—
        search_optimizer = get_search_optimizer()
        
        # LLMä¼˜åŒ–æœç´¢æŸ¥è¯¢
        if search_optimizer and len(original_query) > 2:
            try:
                optimized_query = search_optimizer.invoke({"question": original_query})
                optimized_query = optimized_query.strip()
                
                if len(optimized_query) >= 2 and len(optimized_query) <= len(original_query) * 2:
                    search_query = optimized_query
                    
            except Exception as e:
                print(f"æœç´¢ä¼˜åŒ–å¤±è´¥: {e}")
        
        # æ‰§è¡Œæœç´¢
        search_results = await vector_search.search_similar_documents(
            query=search_query, 
            top_k=top_k,
            use_threshold=False,  # ä¸ä½¿ç”¨é˜ˆå€¼è¿‡æ»¤ï¼Œè¿”å›žæ‰€æœ‰æ‰¾åˆ°çš„ç»“æžœ
            lambda_param=0.7
        )
        
        # å¦‚æžœä¼˜åŒ–æŸ¥è¯¢æ— ç»“æžœï¼Œå°è¯•åŽŸæŸ¥è¯¢
        if not search_results and search_query != original_query:
            search_results = await vector_search.search_similar_documents(
                query=original_query, 
                top_k=top_k,
                use_threshold=False,  # ä¸ä½¿ç”¨é˜ˆå€¼è¿‡æ»¤ï¼Œè¿”å›žæ‰€æœ‰æ‰¾åˆ°çš„ç»“æžœ
                lambda_param=0.7
            )
        
        results = []
        for result in search_results:
            # ä»Žresultä¸­æå–documentå’Œchunkå¯¹è±¡
            document = result.get("document")
            chunk = result.get("chunk")
            
            results.append({
                "document_id": document.id if document else None,
                "document_name": document.filename if document else "æœªçŸ¥æ–‡æ¡£",
                "chunk_content": chunk.content if chunk else "",
                "similarity": round(result.get("similarity", 0), 4),
                "chunk_index": chunk.chunk_index if chunk else 0
            })
        
        return response(
            data={
                "query": original_query,
                "search_query": search_query,
                "results": results,
                "total": len(results),
                "llm_enhanced": search_optimizer is not None,
                "similarity_threshold": SIMILARITY_THRESHOLD,
                "filtered_by_threshold": True
            },
            message="æœç´¢æˆåŠŸ"
        )
        
    except Exception as e:
        print(f"æœç´¢å¤±è´¥: {e}")
        traceback.print_exc()
        return response(code=0, message=f"æœç´¢å¤±è´¥: {str(e)}")


@router.get("/config", summary="èŽ·å–é…ç½®ä¿¡æ¯", description="èŽ·å–å½“å‰ç³»ç»Ÿé…ç½®")
async def get_config():
    """èŽ·å–ç³»ç»Ÿé…ç½®ä¿¡æ¯"""
    return response(
        data={
            "similarity_threshold": SIMILARITY_THRESHOLD,
            "threshold_description": f"ç›¸ä¼¼åº¦é˜ˆå€¼ {SIMILARITY_THRESHOLD:.1%}ï¼Œåªæ˜¾ç¤ºç›¸ä¼¼åº¦å¤§äºŽæ­¤å€¼çš„æ–‡æ¡£"
        },
        message="é…ç½®èŽ·å–æˆåŠŸ"
    )


@router.post("/analyze", summary="é—®é¢˜åˆ†æž(åŒ¿å)", description="ä½¿ç”¨LLMåˆ†æžé—®é¢˜æ„å›¾å’Œå…³é”®è¯ï¼ˆæ— éœ€ç™»å½•ï¼‰")
async def analyze_question(
    question: str = Form(..., description="ç”¨æˆ·é—®é¢˜"),
):
    """é—®é¢˜åˆ†æž - å±•ç¤ºLLMçš„é—®é¢˜ç†è§£èƒ½åŠ›"""
    try:
        # ä½¿ç”¨æ–°çš„ä¼˜åŒ–å™¨æ¨¡å—
        question_optimizer = get_question_optimizer()
        
        if not question_optimizer:
            return response(
                data={
                    "question": question,
                    "analysis": "LLMæœªé…ç½®ï¼Œæ— æ³•è¿›è¡Œæ·±åº¦åˆ†æž",
                    "llm_available": False
                },
                message="LLMæœªé…ç½®"
            )
        
        # ä½¿ç”¨æ–°çš„ç»“æž„åŒ–è¾“å‡º
        analysis_result = optimize_question(question)
        
        return response(
            data={
                "question": question,
                "analysis": analysis_result,
                "llm_available": True
            },
            message="åˆ†æžæˆåŠŸ"
        )
        
    except Exception as e:
        print(f"é—®é¢˜åˆ†æžå¤±è´¥: {e}")
        traceback.print_exc()
        return response(code=0, message=f"é—®é¢˜åˆ†æžå¤±è´¥: {str(e)}")