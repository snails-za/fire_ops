#!/usr/bin/env python3
"""
æ™ºèƒ½æ¨¡å‹å¯¹æ¯”æµ‹è¯•å·¥å…·

æ”¯æŒè‡ªåŠ¨æ£€æµ‹å¿«ç…§ã€è‡ªåŠ¨ä¸‹è½½ã€æ€§èƒ½å¯¹æ¯”å’Œæ™ºèƒ½æ¨è
"""

import os
import sys
import time
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from sklearn.metrics.pairwise import cosine_similarity

from config import HF_HOME, HF_OFFLINE

def setup_environment():
    """è®¾ç½®ç¯å¢ƒå˜é‡"""
    os.environ["HF_HOME"] = HF_HOME
    os.environ["TRANSFORMERS_CACHE"] = HF_HOME
    os.environ["HF_HUB_CACHE"] = HF_HOME
    
    os.makedirs(HF_HOME, exist_ok=True)

def find_local_model_path(model_name):
    """æŸ¥æ‰¾æœ¬åœ°æ¨¡å‹è·¯å¾„"""
    # HuggingFaceå°† '/' è½¬æ¢ä¸º '--'
    local_model_name = model_name.replace('/', '--')
    local_model_path = os.path.join(HF_HOME, f"models--{local_model_name}")
    
    if os.path.exists(local_model_path):
        # æ£€æŸ¥æ˜¯å¦æœ‰snapshotsç›®å½•
        snapshots_dir = os.path.join(local_model_path, "snapshots")
        if os.path.exists(snapshots_dir):
            snapshots = [d for d in os.listdir(snapshots_dir) 
                        if os.path.isdir(os.path.join(snapshots_dir, d))]
            if snapshots:
                latest_snapshot = os.path.join(snapshots_dir, snapshots[0])
                return latest_snapshot
        return local_model_path
    return None

def download_model_if_needed(model_name):
    """å¦‚æœéœ€è¦åˆ™ä¸‹è½½æ¨¡å‹"""
    print(f"ğŸ“¥ ä¸‹è½½æ¨¡å‹: {model_name}")
    
    # ä¸´æ—¶ç¦ç”¨ç¦»çº¿æ¨¡å¼è¿›è¡Œä¸‹è½½
    original_offline = os.environ.get("TRANSFORMERS_OFFLINE")
    original_hub_offline = os.environ.get("HF_HUB_OFFLINE")
    
    if "TRANSFORMERS_OFFLINE" in os.environ:
        del os.environ["TRANSFORMERS_OFFLINE"]
    if "HF_HUB_OFFLINE" in os.environ:
        del os.environ["HF_HUB_OFFLINE"]
    
    try:
        from sentence_transformers import SentenceTransformer
        
        print(f"ğŸŒ æ­£åœ¨ä»HuggingFaceä¸‹è½½...")
        start_time = time.time()
        
        model = SentenceTransformer(model_name, cache_folder=HF_HOME)
        
        download_time = time.time() - start_time
        print(f"âœ… ä¸‹è½½å®Œæˆï¼è€—æ—¶: {download_time:.2f}ç§’")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return False
        
    finally:
        # æ¢å¤åŸå§‹ç¦»çº¿è®¾ç½®
        if original_offline:
            os.environ["TRANSFORMERS_OFFLINE"] = original_offline
        if original_hub_offline:
            os.environ["HF_HUB_OFFLINE"] = original_hub_offline

def test_model_performance(model_name, test_texts):
    """æµ‹è¯•æ¨¡å‹æ€§èƒ½"""
    print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹: {model_name}")
    print("-" * 60)
    
    # 1. æ£€æŸ¥æœ¬åœ°æ¨¡å‹
    local_model_path = find_local_model_path(model_name)
    
    if not local_model_path:
        print("ğŸ“­ æœ¬åœ°æœªæ‰¾åˆ°æ¨¡å‹ï¼Œå¼€å§‹ä¸‹è½½...")
        if not download_model_if_needed(model_name):
            print(f"âŒ æ¨¡å‹ {model_name} ä¸‹è½½å¤±è´¥")
            return None
        
        # é‡æ–°æŸ¥æ‰¾ä¸‹è½½åçš„æ¨¡å‹
        local_model_path = find_local_model_path(model_name)
        if not local_model_path:
            print(f"âŒ ä¸‹è½½åä»æœªæ‰¾åˆ°æ¨¡å‹: {model_name}")
            return None
    else:
        print(f"âœ… æ‰¾åˆ°æœ¬åœ°æ¨¡å‹å¿«ç…§")
    
    try:
        from sentence_transformers import SentenceTransformer
        
        # 2. åŠ è½½æ¨¡å‹ - ä¼˜å…ˆä½¿ç”¨æœ¬åœ°è·¯å¾„
        start_time = time.time()
        
        # è®¾ç½®ä¸´æ—¶ç¦»çº¿æ¨¡å¼ç¡®ä¿ä½¿ç”¨æœ¬åœ°æ¨¡å‹
        original_offline = os.environ.get("TRANSFORMERS_OFFLINE")
        original_hub_offline = os.environ.get("HF_HUB_OFFLINE")
        
        os.environ["TRANSFORMERS_OFFLINE"] = "1"
        os.environ["HF_HUB_OFFLINE"] = "1"
        
        try:
            model = SentenceTransformer(local_model_path)
            load_method = "æœ¬åœ°å¿«ç…§"
        except:
            # å¦‚æœæœ¬åœ°åŠ è½½å¤±è´¥ï¼Œå°è¯•åœ¨çº¿åŠ è½½
            if original_offline:
                os.environ["TRANSFORMERS_OFFLINE"] = original_offline
            else:
                del os.environ["TRANSFORMERS_OFFLINE"]
            if original_hub_offline:
                os.environ["HF_HUB_OFFLINE"] = original_hub_offline
            else:
                del os.environ["HF_HUB_OFFLINE"]
            
            model = SentenceTransformer(model_name, cache_folder=HF_HOME)
            load_method = "åœ¨çº¿åŠ è½½"
        
        load_time = time.time() - start_time
        
        # 3. ç¼–ç æµ‹è¯•
        encode_start = time.time()
        embeddings = model.encode(test_texts)
        encode_time = time.time() - encode_start
        
        print(f"â±ï¸  åŠ è½½æ—¶é—´: {load_time:.2f}ç§’ ({load_method})")
        print(f"âš¡ ç¼–ç æ—¶é—´: {encode_time:.3f}ç§’")
        print(f"ğŸ“Š å‘é‡ç»´åº¦: {embeddings.shape}")
        print(f"ğŸ”¢ å¹³å‡æ¯æ–‡æœ¬: {encode_time/len(test_texts):.3f}ç§’")
        
        # æ¢å¤åŸå§‹ç¯å¢ƒè®¾ç½®
        if original_offline:
            os.environ["TRANSFORMERS_OFFLINE"] = original_offline
        elif "TRANSFORMERS_OFFLINE" in os.environ:
            del os.environ["TRANSFORMERS_OFFLINE"]
            
        if original_hub_offline:
            os.environ["HF_HUB_OFFLINE"] = original_hub_offline
        elif "HF_HUB_OFFLINE" in os.environ:
            del os.environ["HF_HUB_OFFLINE"]
        
        # 4. è®¡ç®—ç›¸ä¼¼åº¦
        if len(embeddings) >= 3:
            
            # ä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦
            sim_zh = cosine_similarity([embeddings[0]], [embeddings[2]])[0][0]
            # ä¸­è‹±æ–‡ç›¸ä¼¼åº¦
            sim_zh_en = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
            
            print(f"ğŸ”— ä¸­æ–‡ç›¸ä¼¼åº¦: {sim_zh:.4f}")
            print(f"ğŸŒ ä¸­è‹±ç›¸ä¼¼åº¦: {sim_zh_en:.4f}")
            
            return {
                "load_time": load_time,
                "encode_time": encode_time,
                "dimensions": embeddings.shape[1],
                "zh_similarity": sim_zh,
                "zh_en_similarity": sim_zh_en,
                "load_method": load_method
            }
        
        return {
            "load_time": load_time,
            "encode_time": encode_time,
            "dimensions": embeddings.shape[1],
            "load_method": load_method
        }
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return None

def compare_models():
    """å¯¹æ¯”ä¸åŒæ¨¡å‹"""
    # æµ‹è¯•æ–‡æœ¬ - åŒ…å«ä¸­è‹±æ–‡å¯¹ç…§
    test_texts = [
        "è¿™æ˜¯ä¸€ä¸ªå…³äºäººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ çš„ä¸­æ–‡æ–‡æ¡£ï¼Œè®¨è®ºäº†æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨ã€‚",
        "This is an English document about artificial intelligence and machine learning, discussing deep learning applications in NLP.",
        "æœ¬æ–‡æ¡£ä»‹ç»äº†RAGæ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼Œä»¥åŠå¦‚ä½•åœ¨å®é™…é¡¹ç›®ä¸­åº”ç”¨å‘é‡æ•°æ®åº“è¿›è¡Œè¯­ä¹‰æœç´¢ã€‚",
        "The document explains RAG retrieval-augmented generation technology and vector database applications."
    ]
    
    # è¦æµ‹è¯•çš„æ¨¡å‹
    models = [
        {
            "name": "å½“å‰æ¨¡å‹",
            "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            "description": "å¤šè¯­è¨€é€šç”¨æ¨¡å‹"
        },
        {
            "name": "BGEä¸­æ–‡æ¨¡å‹", 
            "model": "BAAI/bge-small-zh-v1.5",
            "description": "ç™¾åº¦BGEä¸­æ–‡ä¼˜åŒ–æ¨¡å‹"
        }
    ]
    
    results = {}
    
    print("ğŸš€ å¼€å§‹æ™ºèƒ½æ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    print("ğŸ“ æµ‹è¯•å†…å®¹:")
    print("   - æ¨¡å‹åŠ è½½é€Ÿåº¦")
    print("   - æ–‡æœ¬ç¼–ç æ€§èƒ½") 
    print("   - ä¸­æ–‡è¯­ä¹‰ç›¸ä¼¼åº¦")
    print("   - ä¸­è‹±æ–‡è·¨è¯­è¨€æ•ˆæœ")
    print("=" * 60)
    
    for model_info in models:
        result = test_model_performance(model_info["model"], test_texts)
        if result:
            results[model_info["name"]] = result
            results[model_info["name"]]["description"] = model_info["description"]
    
    # æ‰“å°å¯¹æ¯”ç»“æœ
    if len(results) >= 2:
        print("\nğŸ“Š æ™ºèƒ½å¯¹æ¯”ç»“æœ")
        print("=" * 60)
        
        print(f"{'æŒ‡æ ‡':<15} {'å½“å‰æ¨¡å‹':<20} {'BGEæ¨¡å‹':<20} {'ä¼˜åŠ¿':<10}")
        print("-" * 70)
        
        current = results.get("å½“å‰æ¨¡å‹", {})
        bge = results.get("BGEä¸­æ–‡æ¨¡å‹", {})
        
        if current and bge:
            # åŠ è½½æ—¶é—´å¯¹æ¯”
            load_winner = "BGE" if bge["load_time"] < current["load_time"] else "å½“å‰"
            print(f"{'åŠ è½½æ—¶é—´':<15} {current['load_time']:.2f}ç§’({current.get('load_method', 'N/A'):<8}) {bge['load_time']:.2f}ç§’({bge.get('load_method', 'N/A'):<8}) {load_winner}")
            
            # ç¼–ç æ—¶é—´å¯¹æ¯”
            encode_winner = "BGE" if bge["encode_time"] < current["encode_time"] else "å½“å‰"
            print(f"{'ç¼–ç æ—¶é—´':<15} {current['encode_time']:.3f}ç§’{'':<12} {bge['encode_time']:.3f}ç§’{'':<12} {encode_winner}")
            
            # å‘é‡ç»´åº¦å¯¹æ¯”
            dim_winner = "BGE" if bge["dimensions"] > current["dimensions"] else "å½“å‰"
            print(f"{'å‘é‡ç»´åº¦':<15} {current['dimensions']}{'':<16} {bge['dimensions']}{'':<16} {dim_winner}")
            
            # ä¸­æ–‡ç›¸ä¼¼åº¦å¯¹æ¯”
            if "zh_similarity" in current and "zh_similarity" in bge:
                zh_winner = "BGE" if bge["zh_similarity"] > current["zh_similarity"] else "å½“å‰"
                print(f"{'ä¸­æ–‡ç›¸ä¼¼åº¦':<15} {current['zh_similarity']:.4f}{'':<14} {bge['zh_similarity']:.4f}{'':<14} {zh_winner}")
    
    return results

def get_recommendation(results):
    """è·å–æ™ºèƒ½æ¨èå»ºè®®"""
    print("\nğŸ’¡ æ™ºèƒ½æ¨èå»ºè®®")
    print("=" * 60)
    
    if "BGEä¸­æ–‡æ¨¡å‹" in results and "å½“å‰æ¨¡å‹" in results:
        bge = results["BGEä¸­æ–‡æ¨¡å‹"]
        current = results["å½“å‰æ¨¡å‹"]
        
        print("ğŸ¯ åŸºäºæµ‹è¯•ç»“æœçš„å»ºè®®:")
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        bge_score = 0
        current_score = 0
        
        # ä¸­æ–‡ç›¸ä¼¼åº¦æƒé‡æœ€é«˜
        if "zh_similarity" in bge and "zh_similarity" in current:
            if bge["zh_similarity"] > current["zh_similarity"]:
                bge_score += 3
                print("   âœ… BGEæ¨¡å‹ä¸­æ–‡è¯­ä¹‰ç†è§£æ›´å‡†ç¡® (+3åˆ†)")
            else:
                current_score += 3
                print("   âœ… å½“å‰æ¨¡å‹ä¸­æ–‡è¯­ä¹‰ç†è§£æ›´å‡†ç¡® (+3åˆ†)")
        
        # å‘é‡ç»´åº¦
        if bge["dimensions"] > current["dimensions"]:
            bge_score += 2
            print("   âœ… BGEæ¨¡å‹å‘é‡ç»´åº¦æ›´é«˜ï¼Œè¡¨è¾¾èƒ½åŠ›æ›´å¼º (+2åˆ†)")
        else:
            current_score += 2
            print("   âœ… å½“å‰æ¨¡å‹å‘é‡ç»´åº¦é€‚ä¸­ï¼ŒèŠ‚çœå­˜å‚¨ç©ºé—´ (+2åˆ†)")
        
        # ç¼–ç é€Ÿåº¦
        if bge["encode_time"] < current["encode_time"]:
            bge_score += 1
            print("   âœ… BGEæ¨¡å‹ç¼–ç é€Ÿåº¦æ›´å¿« (+1åˆ†)")
        else:
            current_score += 1
            print("   âœ… å½“å‰æ¨¡å‹ç¼–ç é€Ÿåº¦æ›´å¿« (+1åˆ†)")
        
        print(f"\nğŸ“Š ç»¼åˆè¯„åˆ†:")
        print(f"   BGEæ¨¡å‹: {bge_score}åˆ†")
        print(f"   å½“å‰æ¨¡å‹: {current_score}åˆ†")
        
        if bge_score > current_score:
            print(f"\nğŸ† æ¨èä½¿ç”¨BGEæ¨¡å‹ï¼")
            print("ğŸ”§ åˆ‡æ¢æ–¹æ³•:")
            print("   åœ¨ config.py ä¸­ä¿®æ”¹:")
            print('   EMBEDDING_MODEL = "BAAI/bge-small-zh-v1.5"')
            print('   EMBEDDING_DIMENSION = 512')
        else:
            print(f"\nğŸ† å»ºè®®ä¿æŒå½“å‰æ¨¡å‹ï¼")
            print("ğŸ’¡ å½“å‰æ¨¡å‹å·²ç»å¾ˆå¥½åœ°æ»¡è¶³éœ€æ±‚")
        
        print("\nâš ï¸  åˆ‡æ¢æ³¨æ„äº‹é¡¹:")
        print("   - åˆ‡æ¢æ¨¡å‹åéœ€è¦é‡æ–°å¤„ç†å·²æœ‰æ–‡æ¡£")
        print("   - æ–°æ¨¡å‹å‘é‡ä¸æ—§æ¨¡å‹ä¸å…¼å®¹")
        print("   - å»ºè®®å…ˆå¤‡ä»½ç°æœ‰å‘é‡æ•°æ®")
    
    else:
        print("âŒ æ— æ³•è·å–å®Œæ•´æµ‹è¯•ç»“æœï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ æ™ºèƒ½æ¨¡å‹å¯¹æ¯”æµ‹è¯•å·¥å…·")
    print("=" * 60)
    print("ğŸ“‹ åŠŸèƒ½:")
    print("   âœ… è‡ªåŠ¨æ£€æµ‹æœ¬åœ°æ¨¡å‹å¿«ç…§")
    print("   âœ… ç¼ºå¤±æ¨¡å‹è‡ªåŠ¨ä¸‹è½½")
    print("   âœ… å¤šæ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    print("   âœ… ä¸­æ–‡æ•ˆæœè¯„ä¼°")
    print("   âœ… æ™ºèƒ½æ¨èå»ºè®®")
    print("-" * 60)
    
    setup_environment()
    
    try:
        results = compare_models()
        get_recommendation(results)
        
        print(f"\nğŸ‰ å¯¹æ¯”æµ‹è¯•å®Œæˆï¼")
        print("ğŸ’¡ æ‚¨å¯ä»¥æ ¹æ®æµ‹è¯•ç»“æœé€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("ğŸ”§ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œç¯å¢ƒé…ç½®")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
