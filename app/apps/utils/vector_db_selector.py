"""
ç®€å•çš„å‘é‡æ•°æ®åº“é€‰æ‹©å™¨

æ”¯æŒChromaDBå’ŒQdrantä¸¤ä¸ªæ•°æ®åº“çš„åˆ‡æ¢
"""
import traceback
from typing import List, Dict, Any

import torch
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from langchain_qdrant import Qdrant
from qdrant_client import QdrantClient
from qdrant_client.http.models import Filter, FieldCondition, MatchValue
from qdrant_client.http.models import VectorParams

from apps.models.document import Document as DocumentModel, DocumentChunk
from apps.utils.common import get_local_model_path
from config import CHROMA_PERSIST_DIRECTORY, CHROMA_COLLECTION
from config import (
    EMBEDDING_MODEL, HF_HOME, HF_OFFLINE,
    QDRANT_HOST, QDRANT_PORT, QDRANT_COLLECTION_NAME
)
from config import VECTOR_DB_TYPE


class VectorDBSelector:
    """å‘é‡æ•°æ®åº“é€‰æ‹©å™¨"""

    def __init__(self):
        self.db_type = VECTOR_DB_TYPE
        self.vectorstore = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self._init_database()

    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        if self.db_type == "qdrant":
            self._init_qdrant()
        else:
            self._init_chroma()

    def _init_chroma(self):
        """åˆå§‹åŒ–ChromaDB"""

        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        local_model_path = get_local_model_path(EMBEDDING_MODEL, HF_HOME)

        if local_model_path and HF_OFFLINE:
            embeddings = HuggingFaceEmbeddings(
                model_name=local_model_path,
                model_kwargs={'device': self.device},
                encode_kwargs={'normalize_embeddings': True}
            )
        else:
            embeddings = HuggingFaceEmbeddings(
                model_name=EMBEDDING_MODEL,
                cache_folder=HF_HOME,
                model_kwargs={'device': self.device},
                encode_kwargs={'normalize_embeddings': True}
            )

        # åˆå§‹åŒ–ChromaDB
        self.vectorstore = Chroma(
            collection_name=CHROMA_COLLECTION,
            embedding_function=embeddings,
            persist_directory=CHROMA_PERSIST_DIRECTORY,
        )
        print("âœ… ä½¿ç”¨ChromaDBå‘é‡å­˜å‚¨")

    def _init_qdrant(self):
        """åˆå§‹åŒ– Qdrantï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            host, port, collection_name = QDRANT_HOST, QDRANT_PORT, QDRANT_COLLECTION_NAME

            # âœ… å¿…é¡»ç”¨ url= æ˜¾å¼æŒ‡å®š HTTP è®¿é—®ï¼Œå¦åˆ™é»˜è®¤èµ° gRPCï¼
            client = QdrantClient(url=f"http://{host}:{port}", timeout=30)
            print(f"ğŸŒ æ­£åœ¨è¿æ¥ Qdrant: http://{host}:{port}")

            # âœ… åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
            local_model_path = get_local_model_path(EMBEDDING_MODEL, HF_HOME)
            model_name = local_model_path or EMBEDDING_MODEL
            embeddings = HuggingFaceEmbeddings(
                model_name=model_name,
                cache_folder=HF_HOME,
                model_kwargs={'device': self.device},
                encode_kwargs={'normalize_embeddings': True},
            )

            # âœ… å¦‚æœ collection ä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»º
            if not client.collection_exists(collection_name):
                dim = embeddings.client.get_sentence_embedding_dimension()
                client.create_collection(
                    collection_name=collection_name,
                    vectors_config=VectorParams(size=dim, distance="Cosine")
                )
                print(f"âœ… è‡ªåŠ¨åˆ›å»º Qdrant collection: {collection_name} (dim={dim})")

            # âœ… åˆå§‹åŒ– LangChain å‘é‡å­˜å‚¨
            self.vectorstore = Qdrant(
                client=client,
                collection_name=collection_name,
                embeddings=embeddings,
            )
            print("âœ… ä½¿ç”¨Qdrantå‘é‡å­˜å‚¨")

        except Exception as e:
            traceback.print_exc()
            print(f"âš ï¸ Qdrantåˆå§‹åŒ–å¤±è´¥: {type(e).__name__}: {e}ï¼Œå›é€€åˆ°ChromaDB")
            self.db_type = "chroma"
            self._init_chroma()

    async def add_documents_from_chunks(self, document_id: int, chunks: List[str], chunk_objects: List,
                                        metadata: Dict[str, Any] = None) -> List[str]:
        """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨"""
        try:
            if not chunks or not chunk_objects:
                raise Exception("æ–‡æ¡£å—ä¸ºç©º")

            # åˆ›å»ºLangChainæ–‡æ¡£å¯¹è±¡
            documents = []
            chunk_ids = []

            for i, (chunk_text, chunk_obj) in enumerate(zip(chunks, chunk_objects)):
                doc_metadata = {
                    "document_id": document_id,
                    "chunk_id": chunk_obj.id,
                    "chunk_index": i,
                    "source": metadata.get("filename",
                                           f"document_{document_id}") if metadata else f"document_{document_id}",
                }

                langchain_doc = Document(
                    page_content=chunk_text,
                    metadata=doc_metadata
                )

                documents.append(langchain_doc)
                chunk_ids.append(str(chunk_obj.id))

            # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
            if documents:
                self.vectorstore.add_documents(documents)

            return chunk_ids

        except Exception as e:
            traceback.print_exc()
            raise Exception(f"æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨å¤±è´¥: {e}")

    async def search_similar_documents(self, query: str, top_k: int = 5, use_threshold: bool = True) -> List[
        Dict[str, Any]]:
        """æœç´¢ç›¸ä¼¼æ–‡æ¡£"""
        try:
            # æ‰§è¡Œæœç´¢
            results = self.vectorstore.similarity_search_with_score(query, k=top_k)

            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            all_results = []
            filtered_results = []

            for doc, distance in results:
                similarity = max(0.0, 1.0 - distance)

                metadata = doc.metadata
                document_id = metadata.get('document_id')
                chunk_id = metadata.get('chunk_id')

                if document_id and chunk_id:
                    try:

                        # è·å–æ•°æ®åº“ä¸­çš„æ–‡æ¡£å’Œå—ä¿¡æ¯
                        document = await DocumentModel.get_or_none(id=document_id)
                        chunk = await DocumentChunk.get_or_none(id=chunk_id)

                        if document and chunk:
                            result_item = {
                                'document': document,
                                'chunk': chunk,
                                'similarity': similarity,
                                'metadata': metadata,
                                'above_threshold': similarity >= 0.6  # ä½¿ç”¨å›ºå®šé˜ˆå€¼
                            }

                            all_results.append(result_item)

                            # å¦‚æœä½¿ç”¨é˜ˆå€¼è¿‡æ»¤ï¼Œåªä¿ç•™ç›¸ä¼¼åº¦å¤§äºé˜ˆå€¼çš„ç»“æœ
                            if use_threshold and similarity >= 0.6:
                                filtered_results.append(result_item)
                    except Exception as e:
                        print(f"å¤„ç†æœç´¢ç»“æœé¡¹å¤±è´¥: {e}")
                        continue

            # é€‰æ‹©è¿”å›ç»“æœ
            if filtered_results:
                filtered_results.sort(key=lambda x: x['similarity'], reverse=True)
                return filtered_results[:top_k]
            elif all_results:
                all_results.sort(key=lambda x: x['similarity'], reverse=True)
                return all_results[:min(top_k, 3)]
            else:
                return []

        except Exception as e:
            traceback.print_exc()
            print(f"æœç´¢ç›¸ä¼¼æ–‡æ¡£å¤±è´¥: {e}")
            return []

    async def delete_document(self, document_id: int):
        """åˆ é™¤æ–‡æ¡£"""
        try:
            if self.db_type == "qdrant":
                # Qdrantåˆ é™¤
                self.vectorstore.client.delete(
                    collection_name=QDRANT_COLLECTION_NAME,
                    points_selector=Filter(
                        must=[
                            FieldCondition(
                                key="document_id",
                                match=MatchValue(value=document_id)
                            )
                        ]
                    )
                )
            else:
                # ChromaDBåˆ é™¤
                self.vectorstore._collection.delete(where={"document_id": document_id})

            print(f"âœ… æˆåŠŸåˆ é™¤æ–‡æ¡£ {document_id} çš„å‘é‡æ•°æ®")

        except Exception as e:
            traceback.print_exc()
            raise Exception(f"åˆ é™¤æ–‡æ¡£ {document_id} å‘é‡æ•°æ®å¤±è´¥: {e}")


vector_search = VectorDBSelector()
print("âœ… ä½¿ç”¨LangChainå‘é‡å­˜å‚¨")
