#!/usr/bin/env python3
"""
æ¨¡å‹åŠ è½½éªŒè¯è„šæœ¬

æ”¯æŒä»å¿«ç…§ç›´æ¥åŠ è½½å·²ä¸‹è½½çš„æ¨¡å‹
"""

import os
import sys
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from sklearn.metrics.pairwise import cosine_similarity

from config import EMBEDDING_MODEL, HF_HOME, HF_OFFLINE

def setup_environment():
    """è®¾ç½®ç¯å¢ƒå˜é‡"""
    os.environ["HF_HOME"] = HF_HOME
    os.environ["TRANSFORMERS_CACHE"] = HF_HOME
    os.environ["HF_HUB_CACHE"] = HF_HOME
    
    if HF_OFFLINE:
        os.environ["TRANSFORMERS_OFFLINE"] = "1"
        os.environ["HF_HUB_OFFLINE"] = "1"
    
    os.makedirs(HF_HOME, exist_ok=True)

def find_local_model_path(model_name):
    """æŸ¥æ‰¾æœ¬åœ°æ¨¡å‹è·¯å¾„"""
    # HuggingFaceå°† '/' è½¬æ¢ä¸º '--'
    local_model_name = model_name.replace('/', '--')
    local_model_path = os.path.join(HF_HOME, f"models--{local_model_name}")
    
    if os.path.exists(local_model_path):
        print(f"ğŸ“ æ‰¾åˆ°æ¨¡å‹ç›®å½•: {local_model_path}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰snapshotsç›®å½•
        snapshots_dir = os.path.join(local_model_path, "snapshots")
        if os.path.exists(snapshots_dir):
            snapshots = [d for d in os.listdir(snapshots_dir) 
                        if os.path.isdir(os.path.join(snapshots_dir, d))]
            if snapshots:
                latest_snapshot = os.path.join(snapshots_dir, snapshots[0])
                print(f"ğŸ“¸ æ‰¾åˆ°å¿«ç…§: {snapshots[0]}")
                print(f"ğŸ¯ å¿«ç…§è·¯å¾„: {latest_snapshot}")
                return latest_snapshot
        
        print(f"ğŸ¯ ä½¿ç”¨æ¨¡å‹ç›®å½•: {local_model_path}")
        return local_model_path
    
    return None

def verify_model_files(model_path):
    """éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§"""
    print(f"ğŸ” éªŒè¯æ¨¡å‹æ–‡ä»¶: {model_path}")
    
    required_files = [
        "config.json",
        "modules.json", 
        "sentence_bert_config.json"
    ]
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_files = ["model.safetensors", "pytorch_model.bin"]
    has_model_file = any(os.path.exists(os.path.join(model_path, f)) for f in model_files)
    
    # æ£€æŸ¥tokenizeræ–‡ä»¶
    tokenizer_files = ["tokenizer.json", "vocab.txt"]
    has_tokenizer_file = any(os.path.exists(os.path.join(model_path, f)) for f in tokenizer_files)
    
    missing_files = []
    for file in required_files:
        file_path = os.path.join(model_path, file)
        if os.path.exists(file_path):
            print(f"   âœ… {file}")
        else:
            print(f"   âŒ {file} (ç¼ºå¤±)")
            missing_files.append(file)
    
    if has_model_file:
        print(f"   âœ… æ¨¡å‹æƒé‡æ–‡ä»¶")
    else:
        print(f"   âŒ æ¨¡å‹æƒé‡æ–‡ä»¶ (ç¼ºå¤±)")
        missing_files.append("model weights")
    
    if has_tokenizer_file:
        print(f"   âœ… åˆ†è¯å™¨æ–‡ä»¶")
    else:
        print(f"   âŒ åˆ†è¯å™¨æ–‡ä»¶ (ç¼ºå¤±)")
        missing_files.append("tokenizer")
    
    return len(missing_files) == 0

def download_model_if_needed():
    """å¦‚æœéœ€è¦åˆ™ä¸‹è½½æ¨¡å‹"""
    print("ğŸ“¥ æ¨¡å‹ä¸å­˜åœ¨ï¼Œå¼€å§‹ä¸‹è½½...")
    
    # ä¸´æ—¶ç¦ç”¨ç¦»çº¿æ¨¡å¼è¿›è¡Œä¸‹è½½
    original_offline = os.environ.get("TRANSFORMERS_OFFLINE")
    original_hub_offline = os.environ.get("HF_HUB_OFFLINE")
    
    if "TRANSFORMERS_OFFLINE" in os.environ:
        del os.environ["TRANSFORMERS_OFFLINE"]
    if "HF_HUB_OFFLINE" in os.environ:
        del os.environ["HF_HUB_OFFLINE"]
    
    try:
        from sentence_transformers import SentenceTransformer
        
        print(f"ğŸŒ æ­£åœ¨ä»HuggingFaceä¸‹è½½: {EMBEDDING_MODEL}")
        start_time = time.time()
        
        model = SentenceTransformer(EMBEDDING_MODEL, cache_folder=HF_HOME)
        
        download_time = time.time() - start_time
        print(f"âœ… ä¸‹è½½å®Œæˆï¼è€—æ—¶: {download_time:.2f}ç§’")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return False
        
    finally:
        # æ¢å¤åŸå§‹ç¦»çº¿è®¾ç½®
        if original_offline:
            os.environ["TRANSFORMERS_OFFLINE"] = original_offline
        if original_hub_offline:
            os.environ["HF_HUB_OFFLINE"] = original_hub_offline

def load_and_verify_model():
    """åŠ è½½å¹¶éªŒè¯æ¨¡å‹"""
    print(f"ğŸ” æ¨¡å‹: {EMBEDDING_MODEL}")
    print(f"ğŸ“ ç¼“å­˜: {HF_HOME}")
    print(f"ğŸ”’ ç¦»çº¿: {HF_OFFLINE}")
    print("-" * 50)
    
    # 1. æŸ¥æ‰¾æœ¬åœ°æ¨¡å‹
    local_model_path = find_local_model_path(EMBEDDING_MODEL)
    
    if not local_model_path:
        print("ğŸ“­ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹")
        
        # å¦‚æœç¦»çº¿æ¨¡å¼ï¼Œæç¤ºç”¨æˆ·
        if HF_OFFLINE:
            print("âš ï¸  å½“å‰ä¸ºç¦»çº¿æ¨¡å¼ï¼Œä½†æ¨¡å‹ä¸å­˜åœ¨")
            print("ğŸ”„ ä¸´æ—¶åˆ‡æ¢åˆ°åœ¨çº¿æ¨¡å¼è¿›è¡Œä¸‹è½½...")
        
        # å°è¯•ä¸‹è½½æ¨¡å‹
        if not download_model_if_needed():
            return False
        
        # é‡æ–°æŸ¥æ‰¾ä¸‹è½½åçš„æ¨¡å‹
        local_model_path = find_local_model_path(EMBEDDING_MODEL)
        if not local_model_path:
            print("âŒ ä¸‹è½½åä»æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
            return False
    
    # 2. éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
    if not verify_model_files(local_model_path):
        print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´ï¼Œå°è¯•é‡æ–°ä¸‹è½½...")
        
        # æ–‡ä»¶ä¸å®Œæ•´ï¼Œå°è¯•é‡æ–°ä¸‹è½½
        if not download_model_if_needed():
            return False
        
        # é‡æ–°éªŒè¯
        local_model_path = find_local_model_path(EMBEDDING_MODEL)
        if not local_model_path or not verify_model_files(local_model_path):
            print("âŒ é‡æ–°ä¸‹è½½åæ–‡ä»¶ä»ä¸å®Œæ•´")
            return False
    
    try:
        from sentence_transformers import SentenceTransformer
        
        # 3. å°è¯•ç›´æ¥ä»å¿«ç…§è·¯å¾„åŠ è½½
        print(f"\nğŸ“¥ ä»å¿«ç…§åŠ è½½æ¨¡å‹...")
        start_time = time.time()
        
        if HF_OFFLINE:
            # ç¦»çº¿æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨æœ¬åœ°è·¯å¾„
            model = SentenceTransformer(local_model_path)
            load_method = "å¿«ç…§è·¯å¾„ (ç¦»çº¿)"
        else:
            # åœ¨çº¿æ¨¡å¼ï¼šå…ˆå°è¯•æ¨¡å‹åç§°ï¼Œå¤±è´¥åˆ™ä½¿ç”¨æœ¬åœ°è·¯å¾„
            try:
                model = SentenceTransformer(EMBEDDING_MODEL, cache_folder=HF_HOME)
                load_method = "æ¨¡å‹åç§° (åœ¨çº¿)"
            except:
                model = SentenceTransformer(local_model_path)
                load_method = "å¿«ç…§è·¯å¾„ (é™çº§)"
        
        load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        print(f"   - åŠ è½½æ–¹å¼: {load_method}")
        print(f"   - è€—æ—¶: {load_time:.2f}ç§’")
        
        # 4. æµ‹è¯•ç¼–ç åŠŸèƒ½
        print(f"\nğŸ§ª æµ‹è¯•ç¼–ç åŠŸèƒ½...")
        test_texts = [
            "è¿™æ˜¯ä¸€ä¸ªä¸­æ–‡æµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯æ¨¡å‹çš„ä¸­æ–‡å¤„ç†èƒ½åŠ›ã€‚",
            "This is an English test text for model validation.",
            "RAGç³»ç»Ÿå‘é‡åŒ–æµ‹è¯•ï¼Œæ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯éªŒè¯ã€‚"
        ]
        
        encode_start = time.time()
        embeddings = model.encode(test_texts)
        encode_time = time.time() - encode_start
        
        print(f"âœ… ç¼–ç æµ‹è¯•æˆåŠŸï¼")
        print(f"   - æ–‡æœ¬æ•°é‡: {len(test_texts)}")
        print(f"   - å‘é‡ç»´åº¦: {embeddings.shape}")
        print(f"   - ç¼–ç è€—æ—¶: {encode_time:.3f}ç§’")
        print(f"   - å¹³å‡è€—æ—¶: {encode_time/len(test_texts):.3f}ç§’/æ–‡æœ¬")
        
        # 5. æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—
        print(f"\nğŸ”— æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—...")
        
        # è®¡ç®—ä¸­æ–‡æ–‡æœ¬é—´çš„ç›¸ä¼¼åº¦
        sim_zh = cosine_similarity([embeddings[0]], [embeddings[2]])[0][0]
        sim_zh_en = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
        
        print(f"   - ä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦: {sim_zh:.4f}")
        print(f"   - ä¸­è‹±æ–‡æœ¬ç›¸ä¼¼åº¦: {sim_zh_en:.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ™ºèƒ½æ¨¡å‹ç®¡ç†å·¥å…·")
    print("=" * 50)
    print("ğŸ“‹ åŠŸèƒ½:")
    print("   âœ… è‡ªåŠ¨æ£€æµ‹æœ¬åœ°æ¨¡å‹å¿«ç…§")
    print("   âœ… å¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨ä¸‹è½½")
    print("   âœ… éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§")
    print("   âœ… æµ‹è¯•æ¨¡å‹åŠ è½½å’Œç¼–ç åŠŸèƒ½")
    print("-" * 50)
    
    setup_environment()
    
    success = load_and_verify_model()
    
    if success:
        print("\nğŸ‰ æ¨¡å‹å‡†å¤‡å®Œæˆï¼")
        print("ğŸ“ ç°åœ¨å¯ä»¥å¯åŠ¨RAGç³»ç»Ÿ:")
        print("   fastapi dev asgi.py")
        print("\nğŸ’¡ çŠ¶æ€:")
        print("   âœ… æ¨¡å‹æ–‡ä»¶å®Œæ•´")
        print("   âœ… å¿«ç…§åŠ è½½æ­£å¸¸")
        print("   âœ… ç¼–ç åŠŸèƒ½æ­£å¸¸")
        print("   âœ… å¯ä»¥å¼€å§‹å¤„ç†æ–‡æ¡£")
    else:
        print("\nâŒ æ¨¡å‹å‡†å¤‡å¤±è´¥")
        print("ğŸ”§ è¯·æ£€æŸ¥:")
        print("   - ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("   - ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³")
        print("   - HuggingFaceè®¿é—®æ˜¯å¦æ­£å¸¸")
        print("   - ç¯å¢ƒé…ç½®æ˜¯å¦æ­£ç¡®")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)